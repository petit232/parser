import os
import re
import requests
import base64
from datetime import datetime

# --- ĞœĞĞšĞ¡Ğ˜ĞœĞĞ›Ğ¬ĞĞ«Ğ™ Ğ¡ĞŸĞ ĞĞ’ĞĞ§ĞĞ˜Ğš Ğ¡Ğ¢Ğ ĞĞ Ğ˜ ĞœĞĞ ĞšĞ•Ğ ĞĞ’ ---
COUNTRIES = {
    "belarus": {"keys": ["ğŸ‡§ğŸ‡¾", "by", "belarus", "Ğ±ĞµĞ»Ğ°Ñ€ÑƒÑÑŒ", "Ğ¼Ğ¸Ğ½ÑĞº", "minsk", "msq", "by.adr-cloud.ru", "by.cdn.titun.su"], "flag": "ğŸ‡§ğŸ‡¾"},
    "kazakhstan": {"keys": ["ğŸ‡°ğŸ‡¿", "kazakhstan", "ĞºĞ°Ğ·Ğ°Ñ…ÑÑ‚Ğ°Ğ½", "Ğ°Ğ»Ğ¼Ğ°Ñ‚Ñ‹", "Ğ°ÑÑ‚Ğ°Ğ½Ğ°", "astana", "almaty", "ala", "tse", "kz.adrenaline-fast.ru", "kz1.sky-vault.top", "pavlodar"], "flag": "ğŸ‡°ğŸ‡¿"},
    "germany": {"keys": ["ğŸ‡©ğŸ‡ª", "germany", "Ğ³ĞµÑ€Ğ¼Ğ°Ğ½Ğ¸Ñ", "frankfurt", "berlin", "fra", "falkenstein", "âš¡ï¸de", "germ.adrenaline-fast.ru", "de.cdn.stun.su", "de5.sky-vault.top", "freede.spectrum.vu", "dreieich", "hennigsdorf", "limburg", "nuremberg"], "flag": "ğŸ‡©ğŸ‡ª"},
    "poland": {"keys": ["ğŸ‡µğŸ‡±", "poland", "Ğ¿Ğ¾Ğ»ÑŒÑˆĞ°", "warsaw", "warszawa", "waw", "pl", "plr.strelkavpn.ru"], "flag": "ğŸ‡µğŸ‡±"},
    "usa": {"keys": ["ğŸ‡ºğŸ‡¸", "usa", "ÑÑˆĞ°", "united states", "america", "jfk", "lax", "sjc", "microsoft", "volumedrive", "us"], "flag": "ğŸ‡ºğŸ‡¸"},
    "sweden": {"keys": ["ğŸ‡¸ğŸ‡ª", "sweden", "ÑˆĞ²ĞµÑ†Ğ¸Ñ", "stockholm", "sto", "se", "sw.adr-cloud.ru", "game-sw.adrtun.ru", "secdn16.suio.me", "spÃ¥nga", "Ã¶sthammar"], "flag": "ğŸ‡¸ğŸ‡ª"},
    "netherlands": {"keys": ["ğŸ‡³ğŸ‡±", "netherlands", "Ğ½Ğ¸Ğ´ĞµÑ€Ğ»Ğ°Ğ½Ğ´Ñ‹", "amsterdam", "ams", "nl", "download.lastilhame.monster"], "flag": "ğŸ‡³ğŸ‡±"},
    "latvia_lithuania": {"keys": ["ğŸ‡±ğŸ‡»", "ğŸ‡±ğŸ‡¹", "latvia", "lithuania", "Ğ»Ğ°Ñ‚Ğ²Ğ¸Ñ", "Ğ»Ğ¸Ñ‚Ğ²Ğ°", "riga", "vilnius", "rix", "vno", "lat.adrenaline-fast.ru"], "flag": "ğŸ‡±ğŸ‡»"},
    "russia": {"keys": ["ğŸ‡·ğŸ‡º", "russia", "Ñ€Ğ¾ÑÑĞ¸Ñ", "moscow", "mow", "svo", "dme", "vko", "led", "saint-petersburg", "ru", "rus"], "flag": "ğŸ‡·ğŸ‡º"},
    "singapore": {"keys": ["ğŸ‡¸ğŸ‡¬", "singapore", "ÑĞ¸Ğ½Ğ³Ğ°Ğ¿ÑƒÑ€", "sin", "changi", "sg"], "flag": "ğŸ‡¸ğŸ‡¬"},
    "uk": {"keys": ["ğŸ‡¬ğŸ‡§", "uk", "gb", "united kingdom", "london", "lon", "lhr"], "flag": "ğŸ‡¬ğŸ‡§"},
    "hongkong": {"keys": ["ğŸ‡­ğŸ‡°", "hong kong", "Ğ³Ğ¾Ğ½ĞºĞ¾Ğ½Ğ³", "hkg", "hk"], "flag": "ğŸ‡­ğŸ‡°"},
    "finland": {"keys": ["ğŸ‡«ğŸ‡®", "finland", "Ñ„Ğ¸Ğ½Ğ»ÑĞ½Ğ´Ğ¸Ñ", "helsinki", "hel", "fi"], "flag": "ğŸ‡«ğŸ‡®"},
    "france": {"keys": ["ğŸ‡«ğŸ‡·", "france", "Ñ„Ñ€Ğ°Ğ½Ñ†Ğ¸Ñ", "paris", "cdg", "ovh", "fr"], "flag": "ğŸ‡«ğŸ‡·"}
}

PROTOCOLS = ["vless://", "vmess://", "trojan://", "ss://", "hysteria2://", "tuic://"]

def decode_base64(data):
    """Ğ”ĞµĞºĞ¾Ğ´Ğ¸Ñ€ÑƒĞµÑ‚ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ğ¼Ğ¾Ğµ, ĞµÑĞ»Ğ¸ Ğ¾Ğ½Ğ¾ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ Base64."""
    try:
        data = data.strip()
        if not data: return ""
        missing_padding = len(data) % 4
        if missing_padding:
            data += '=' * (4 - missing_padding)
        return base64.b64decode(data).decode('utf-8', errors='ignore')
    except Exception:
        return data

def get_unique_id(config):
    """Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµÑ‚ ÑƒĞ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ´Ñ€ĞµÑ Ğ¸ Ğ¿Ğ¾Ñ€Ñ‚ ÑĞµÑ€Ğ²ĞµÑ€Ğ° Ğ´Ğ»Ñ ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¸Ñ Ğ´ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ğ¾Ğ²."""
    match = re.search(r'://([^/?#@]+@)?([^/?#:]+:[0-9]+|[^/?#:]+)', config)
    return match.group(2) if match else config

def sanitize_sources(file_path):
    """
    Ğ—Ğ°Ñ‰Ğ¸Ñ‚Ğ° Ğ¾Ñ‚ Ğ·Ğ°Ñ‚ÑƒĞ¿ĞºĞ°: Ñ‡Ğ¸ÑÑ‚Ğ¸Ñ‚ all_sources.txt Ğ¾Ñ‚ Ğ´ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ğ¾Ğ² ÑÑÑ‹Ğ»Ğ¾Ğº, 
    Ğ¼ÑƒÑĞ¾Ñ€Ğ½Ñ‹Ñ… ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ² Ğ¸ Ğ¿ÑƒÑÑ‚Ñ‹Ñ… ÑÑ‚Ñ€Ğ¾Ğº. ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµÑ‚ Ñ„Ğ°Ğ¹Ğ».
    """
    if not os.path.exists(file_path):
        return []
    
    print(f"ĞÑ‡Ğ¸ÑÑ‚ĞºĞ° Ğ¸ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ° {file_path}...")
    with open(file_path, 'r', encoding='utf-8') as f:
        raw_lines = f.read().splitlines()

    clean_sources = []
    seen = set()

    for line in raw_lines:
        # Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ ĞºĞ°Ğ²Ñ‹Ñ‡ĞºĞ¸, Ğ·Ğ°Ğ¿ÑÑ‚Ñ‹Ğµ, Ğ»Ğ¸ÑˆĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ±ĞµĞ»Ñ‹ Ğ¿Ğ¾ ĞºÑ€Ğ°ÑĞ¼
        s = line.strip().strip('",\'').strip()
        
        # ĞŸÑ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ¿ÑƒÑÑ‚Ñ‹Ğµ ÑÑ‚Ñ€Ğ¾ĞºĞ¸ Ğ¸ Ğ´ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ñ‹
        if not s or s in seen:
            continue
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ°: ÑĞ²Ğ»ÑĞµÑ‚ÑÑ Ğ»Ğ¸ ÑÑ‚Ğ¾ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ğ¾Ğ¹ ÑÑÑ‹Ğ»ĞºĞ¾Ğ¹ Ğ¸Ğ»Ğ¸ Ğ¿Ñ€Ğ¾ĞºÑĞ¸-ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³Ğ¾Ğ¼
        if s.startswith("http") or any(proto in s for proto in PROTOCOLS):
            clean_sources.append(s)
            seen.add(s)

    # ĞŸĞµÑ€ĞµĞ·Ğ°Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°ĞµĞ¼ Ñ„Ğ°Ğ¹Ğ»-Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº Ñ‡Ğ¸ÑÑ‚Ñ‹Ğ¼Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write("\n".join(clean_sources))
    
    print(f"ĞÑ‡Ğ¸ÑÑ‚ĞºĞ° Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°. Ğ‘Ñ‹Ğ»Ğ¾: {len(raw_lines)}, ÑÑ‚Ğ°Ğ»Ğ¾: {len(clean_sources)}")
    return clean_sources

def process():
    source_file = 'all_sources.txt'
    
    # Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ñ‡Ğ¸ÑÑ‚Ğ¸Ğ¼ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¸ (Ğ—Ğ°Ñ‰Ğ¸Ñ‚Ğ° Ğ¾Ñ‚ Ğ·Ğ°Ñ‚ÑƒĞ¿ĞºĞ°)
    sources = sanitize_sources(source_file)
    
    if not sources:
        print("Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ² Ğ¿ÑƒÑÑ‚ Ğ¿Ğ¾ÑĞ»Ğµ Ğ¾Ñ‡Ğ¸ÑÑ‚ĞºĞ¸.")
        return

    all_raw_links = []
    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    timestamp_mark = f"\n\n# Last Update: {now}"

    print(f"ĞĞ°Ñ‡Ğ¸Ğ½Ğ°Ñ ÑĞ±Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ· {len(sources)} Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞµĞ½Ğ½Ñ‹Ñ… Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ²...")

    for url in sources:
        if url.startswith("http"):
            try:
                print(f"Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ°: {url}")
                headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
                resp = requests.get(url, headers=headers, timeout=30)
                if resp.status_code == 200:
                    text = resp.text
                    if not any(p in text for p in PROTOCOLS):
                        text = decode_base64(text)
                    
                    found = re.findall(r'(?:vless|vmess|trojan|ss|hysteria2|tuic)://[^\s#"\'<>,]+', text)
                    all_raw_links.extend(found)
                    print(f"--- ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾: {len(found)} ÑˆÑ‚.")
            except Exception as e:
                print(f"--- ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ {url}: {e}")
        elif any(proto in url for proto in PROTOCOLS):
            found = re.findall(r'(?:vless|vmess|trojan|ss|hysteria2|tuic)://[^\s#"\'<>,]+', url)
            all_raw_links.extend(found if found else [url])

    structured_data = {country: set() for country in COUNTRIES}
    mix_data = set()
    unique_check = set()

    print("Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ´ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ğ¾Ğ² ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³Ğ¾Ğ² Ğ¸ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾ ÑÑ‚Ñ€Ğ°Ğ½Ğ°Ğ¼...")

    for config in all_raw_links:
        config = config.strip()
        uid = get_unique_id(config)
        
        if uid in unique_check:
            continue
        unique_check.add(uid)

        config_lower = config.lower()
        assigned = False
        
        # 1. ĞŸĞ¾Ğ¸ÑĞº Ğ¿Ğ¾ Ñ„Ğ»Ğ°Ğ³Ğ°Ğ¼
        for country, info in COUNTRIES.items():
            if info["flag"] in config:
                structured_data[country].add(config)
                assigned = True
                break
        
        # 2. ĞŸĞ¾Ğ¸ÑĞº Ğ¿Ğ¾ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğ¼ ÑĞ»Ğ¾Ğ²Ğ°Ğ¼
        if not assigned:
            for country, info in COUNTRIES.items():
                for key in info["keys"]:
                    key_low = key.lower()
                    if len(key_low) <= 3:
                        if re.search(r'[^a-z0-9]' + re.escape(key_low) + r'[^a-z0-9]', f" {config_lower} "):
                            structured_data[country].add(config)
                            assigned = True
                            break
                    elif key_low in config_lower:
                        structured_data[country].add(config)
                        assigned = True
                        break
                if assigned:
                    break

        mix_data.add(config)

    # Ğ¡ĞĞ¥Ğ ĞĞĞ•ĞĞ˜Ğ•
    print("Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²...")
    for country in COUNTRIES:
        filename = f"{country}.txt"
        configs = sorted(list(structured_data[country]))
        with open(filename, 'w', encoding='utf-8') as f:
            if configs:
                f.write("\n".join(configs))
            f.write(timestamp_mark)

    with open("mix.txt", 'w', encoding='utf-8') as f:
        if mix_data:
            f.write("\n".join(sorted(list(mix_data))))
        f.write(timestamp_mark)

    print(f"Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ğ¾! Ğ’ÑĞµĞ³Ğ¾ ÑƒĞ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑĞµÑ€Ğ²ĞµÑ€Ğ¾Ğ² ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¾: {len(mix_data)}")

if __name__ == "__main__":
    process()
