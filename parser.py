import os
import re
import requests
import base64
import json
import threading
import time
import random
import subprocess
import signal
import sys
import gc
import socket
import uuid
import hashlib
import shutil
from datetime import datetime, timedelta
from urllib.parse import quote, unquote
from concurrent.futures import ThreadPoolExecutor, as_completed

# ==============================================================================
# üöÄ VPN MONSTER ENGINE ULTRA DAEMON - PREMIUM EDITION
# ==============================================================================
# –ê–≤—Ç–æ—Ä: Monster Engine Team
# –í–µ—Ä—Å–∏—è: 4.1.0 (Dynamic Cache Edition)
# –û–ø–∏—Å–∞–Ω–∏–µ: –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –¥–µ–º–æ–Ω —Å —É–º–Ω—ã–º —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º—ã–º –∫—ç—à–µ–º.
# ==============================================================================

# --- –ù–ê–°–¢–†–û–ô–ö–ò –î–ï–ú–û–ù–ê –ò –¢–ê–ô–ú–ï–†–û–í ---
UPDATE_INTERVAL_HOURS = 6       # –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –ø–æ–ª–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –±–∞–∑—ã (–≤ —á–∞—Å–∞—Ö)
WATCHER_INTERVAL_SEC = 2.0      # –ö–∞–∫ —á–∞—Å—Ç–æ –ø—Ä–æ–≤–µ—Ä—è—Ç—å –ª–æ–∫–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã –Ω–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è (–≤ —Å–µ–∫—É–Ω–¥–∞—Ö)
PORT_TIMEOUT = 4.0              # –¢–∞–π–º–∞—É—Ç TCP Ping (–¥–ª—è Hysteria2/Reality)
BLACKLIST_BAIL_DAYS = 7         # –°–∫–æ–ª—å–∫–æ –¥–Ω–µ–π —Ö—Ä–∞–Ω–∏—Ç—å –º–µ—Ä—Ç–≤—ã–µ —É–∑–ª—ã –≤ –±–ª—ç–∫–ª–∏—Å—Ç–µ
CACHE_EXPIRY_DAYS = 30          # –°—Ä–æ–∫ –∂–∏–∑–Ω–∏ –∫—ç—à–∞ GeoIP (–¥–ª—è –∞–∫—Ç—É–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö)

# --- –ù–ê–°–¢–†–û–ô–ö–ò –ü–û–¢–û–ö–û–í –ò API ---
THREAD_COUNT = 150              # –ü–æ—Ç–æ–∫–∏ –¥–ª—è TCP Ping
GEOIP_PARALLEL_LEVEL = 10       # –ü–æ—Ç–æ–∫–∏ –¥–ª—è GeoIP (–∑–∞—â–∏—Ç–∞ –æ—Ç –±–∞–Ω–æ–≤ API)
GEOIP_LIMIT_PER_RUN = 15000     # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–≤–µ—Ä–æ–∫ GeoIP –∑–∞ –æ–¥–∏–Ω —Ü–∏–∫–ª

# --- –§–ê–ô–õ–û–í–ê–Ø –°–ò–°–¢–ï–ú–ê ---
LOCK_FILE = "monster_daemon.lock"
PERSISTENT_BLACKLIST = "persistent_blacklist.txt"
PROCESSED_SOURCES_FILE = "processed_sources.dat"
ALL_SOURCES_FILE = "all_sources.txt"
GEOIP_CACHE_FILE = "geoip_cache.json"

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –°–¢–†–ê–ù (PREMIUM MIRROR DESIGN) ---
COUNTRIES = {
    "belarus": {"flag": "üáßüáæ", "code": "BY", "name": "Belarus"},
    "kazakhstan": {"flag": "üá∞üáø", "code": "KZ", "name": "Kazakhstan"},
    "germany": {"flag": "üá©üá™", "code": "DE", "name": "Germany"},
    "poland": {"flag": "üáµüá±", "code": "PL", "name": "Poland"},
    "usa": {"flag": "üá∫üá∏", "code": "US", "name": "USA"},
    "sweden": {"flag": "üá∏üá™", "code": "SE", "name": "Sweden"},
    "netherlands": {"flag": "üá≥üá±", "code": "NL", "name": "Netherlands"},
    "latvia_lithuania": {"flag": "üá±üáª", "code": "LV", "alt_code": "LT", "name": "Latvia/Lithuania"},
    "russia": {"flag": "üá∑üá∫", "code": "RU", "name": "Russia"},
    "singapore": {"flag": "üá∏üá¨", "code": "SG", "name": "Singapore"},
    "uk": {"flag": "üá¨üáß", "code": "GB", "extra": "UK", "name": "United Kingdom"},
    "hongkong": {"flag": "üá≠üá∞", "code": "HK", "name": "Hong Kong"},
    "finland": {"flag": "üá´üáÆ", "code": "FI", "name": "Finland"},
    "france": {"flag": "üá´üá∑", "code": "FR", "name": "France"}
}

ALLOWED_PROTOCOLS = ["vless://", "vmess://", "trojan://", "ss://", "hysteria2://", "tuic://"]

# --- –ì–õ–û–ë–ê–õ–¨–ù–´–ï –°–û–°–¢–û–Ø–ù–ò–Ø (THREAD-SAFE) ---
IP_CACHE = {} 
CACHE_LOCK = threading.Lock()
BLACKLIST_CACHE = set()
BLACKLIST_LOCK = threading.Lock()
SHOULD_EXIT = False 

# ==============================================================================
# --- –°–ò–°–¢–ï–ú–ê –£–ú–ù–û–ì–û –ö–≠–®–ò–†–û–í–ê–ù–ò–Ø ---
# ==============================================================================

def load_geoip_cache():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∫—ç—à–∞ GeoIP –∏–∑ JSON —Ñ–∞–π–ª–∞."""
    global IP_CACHE
    if os.path.exists(GEOIP_CACHE_FILE):
        try:
            with open(GEOIP_CACHE_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                # –§–∏–ª—å—Ç—Ä—É–µ–º —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏
                now = time.time()
                expiry_sec = CACHE_EXPIRY_DAYS * 86400
                with CACHE_LOCK:
                    IP_CACHE = {k: v for k, v in data.items() if now - v.get('ts', 0) < expiry_sec}
            print(f"üì¶ [Cache] –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(IP_CACHE)} –∑–∞–ø–∏—Å–µ–π –∏–∑ {GEOIP_CACHE_FILE}")
        except Exception as e:
            print(f"üì¶ [Cache] –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫—ç—à–∞: {e}")
            IP_CACHE = {}

def save_geoip_cache():
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫—ç—à–∞ GeoIP –≤ JSON —Ñ–∞–π–ª."""
    with CACHE_LOCK:
        try:
            with open(GEOIP_CACHE_FILE, 'w', encoding='utf-8') as f:
                json.dump(IP_CACHE, f, ensure_ascii=False, indent=4)
        except Exception as e:
            print(f"üì¶ [Cache] –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫—ç—à–∞: {e}")

def remove_from_cache(host):
    """–£–¥–∞–ª–µ–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ö–æ—Å—Ç–∞ –∏–∑ –∫—ç—à–∞ (—Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏)."""
    with CACHE_LOCK:
        if host in IP_CACHE:
            del IP_CACHE[host]
            return True
    return False

# ==============================================================================
# --- –°–ò–°–¢–ï–ú–ù–´–ï –§–£–ù–ö–¶–ò–ò –ò –û–ë–†–ê–ë–û–¢–ß–ò–ö–ò ---
# ==============================================================================

def signal_handler(sig, frame):
    global SHOULD_EXIT
    print("\n[!] –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ü–†–ï–†–´–í–ê–ù–ò–ï: –ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –æ—Å—Ç–∞–Ω–æ–≤–∫–∏.", flush=True)
    SHOULD_EXIT = True
    save_geoip_cache()
    if os.path.exists(LOCK_FILE):
        try: os.remove(LOCK_FILE)
        except: pass

signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)

def get_random_ua():
    uas = [
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36",
        "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:125.0) Gecko/20100101 Firefox/125.0",
        "Mozilla/5.0 (iPhone; CPU iPhone OS 17_4_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.4.1 Mobile/15E148 Safari/604.1"
    ]
    return random.choice(uas)

def atomic_save(filepath, content):
    tmp_file = f"{filepath}.tmp"
    try:
        with open(tmp_file, 'w', encoding='utf-8') as f:
            f.write(content)
        os.replace(tmp_file, filepath)
    except Exception as e:
        print(f"[ERROR] –û—à–∏–±–∫–∞ –∞—Ç–æ–º–∞—Ä–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è {filepath}: {e}")
        if os.path.exists(tmp_file):
            try: os.remove(tmp_file)
            except: pass

def get_file_mod_time(filepath):
    try:
        if os.path.exists(filepath):
            return os.path.getmtime(filepath)
    except: pass
    return 0

# ==============================================================================
# --- –ü–ê–†–°–ò–ù–ì –ò –î–ï–ö–û–î–ò–†–û–í–ê–ù–ò–ï ---
# ==============================================================================

def decode_base64(data):
    try:
        data = re.sub(r'[^a-zA-Z0-9+/=]', '', data)
        if not data: return ""
        missing_padding = len(data) % 4
        if missing_padding: data += '=' * (4 - missing_padding)
        return base64.b64decode(data).decode('utf-8', errors='ignore')
    except Exception: return ""

def encode_base64(data):
    try:
        return base64.b64encode(data.encode('utf-8')).decode('utf-8')
    except Exception: return ""

def get_server_info(config):
    try:
        clean_config = config.split('#')[0].strip()
        if clean_config.startswith("vmess://"):
            decoded = decode_base64(clean_config[8:])
            if decoded:
                v_data = json.loads(decoded)
                return str(v_data.get('add', '')).strip(), str(v_data.get('port', '')).strip()
        
        match = re.search(r'://(?:[^@]+@)?([^:/#\?]+):(\d+)', clean_config)
        if match:
            return match.group(1).strip(), match.group(2).strip()
    except Exception: pass
    return None, None

def beautify_config(config, country_key=None, fallback_code="UN"):
    try:
        if country_key and country_key in COUNTRIES:
            info = COUNTRIES[country_key]
            label = f"‚ù§Ô∏è {info['flag']} {info['name']} | {info['code']} {info['flag']} ‚ù§Ô∏è"
        else:
            code = fallback_code if fallback_code else "UN"
            label = f"‚ù§Ô∏è üåç Global | {code} üåç ‚ù§Ô∏è"
        
        if config.startswith("vmess://"):
            clean_config = config.split('#')[0]
            decoded = decode_base64(clean_config[8:])
            if decoded:
                data = json.loads(decoded)
                data['ps'] = label
                return "vmess://" + encode_base64(json.dumps(data))
        else:
            base_part = config.split('#')[0]
            return f"{base_part}#{quote(label)}"
    except Exception: return config

# ==============================================================================
# --- –°–ï–¢–¨: TCP PING –ò GEOIP –î–í–ò–ñ–û–ö ---
# ==============================================================================

def is_node_alive(host, port, timeout=PORT_TIMEOUT):
    if not host or not port: return False
    if host.startswith(('127.', '192.168.', '10.', '172.16.', '0.')) or host == 'localhost':
        return False
    try:
        port_int = int(port)
        with socket.create_connection((host, port_int), timeout=timeout):
            return True
    except: return False

# API –ü—Ä–æ–≤–∞–π–¥–µ—Ä—ã
def api_01(h): return requests.get(f"http://ip-api.com/json/{h}?fields=status,countryCode", timeout=4).json().get("countryCode")
def api_02(h): return requests.get(f"https://ipwho.is/{h}", timeout=4).json().get("country_code")
def api_03(h): 
    r = requests.get(f"https://ip2c.org/{h}", timeout=4)
    return r.text.split(';')[1] if "1;" in r.text else None
def api_04(h): return requests.get(f"https://freeipapi.com/api/json/{h}", timeout=4).json().get("countryCode")
def api_05(h): return requests.get(f"https://ipapi.co/{h}/json/", timeout=4, headers={'User-Agent': get_random_ua()}).json().get("country_code")

def check_ip_location_smart(host):
    if SHOULD_EXIT: return None
    
    # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤ –≥–æ—Ä—è—á–µ–º –∫—ç—à–µ (–ü–∞–º—è—Ç—å + JSON)
    with CACHE_LOCK:
        if host in IP_CACHE:
            entry = IP_CACHE[host]
            # –ï—Å–ª–∏ –∑–∞–ø–∏—Å—å –Ω–µ –ø—Ä–æ—Å—Ä–æ—á–µ–Ω–∞
            if time.time() - entry.get('ts', 0) < (CACHE_EXPIRY_DAYS * 86400):
                return entry.get('code')
    
    # 2. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —á–µ—Ä–µ–∑ API
    time.sleep(random.uniform(0.2, 0.6))
    providers = [api_01, api_02, api_03, api_04, api_05]
    random.shuffle(providers)
    
    for provider in providers:
        if SHOULD_EXIT: break
        try:
            code = provider(host)
            if code and len(str(code)) == 2:
                code = str(code).upper()
                with CACHE_LOCK:
                    IP_CACHE[host] = {"code": code, "ts": time.time()}
                return code
        except: continue
    
    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º "UN" —á—Ç–æ–±—ã –Ω–µ –º—É—á–∏—Ç—å API
    with CACHE_LOCK:
        IP_CACHE[host] = {"code": "UN", "ts": time.time()}
    return "UN"

# ==============================================================================
# --- –£–ü–†–ê–í–õ–ï–ù–ò–ï –ë–ê–ó–ê–ú–ò –ò –ß–ï–†–ù–´–ú–ò –°–ü–ò–°–ö–ê–ú–ò (DEEP PURGE SYSTEM) ---
# ==============================================================================

def load_persistent_blacklist():
    bl = set()
    if os.path.exists(PERSISTENT_BLACKLIST):
        try:
            with open(PERSISTENT_BLACKLIST, 'r', encoding='utf-8') as f:
                for line in f:
                    parts = line.strip().split('|')
                    if len(parts) >= 2:
                        node_id = parts[0]
                        date_str = parts[1]
                        try:
                            date_obj = datetime.fromisoformat(date_str)
                            if datetime.now() - date_obj < timedelta(days=BLACKLIST_BAIL_DAYS):
                                bl.add(node_id)
                        except: pass
        except: pass
    
    with BLACKLIST_LOCK:
        global BLACKLIST_CACHE
        BLACKLIST_CACHE = bl.copy()
    print(f"üõ°Ô∏è Persistent Blacklist –∑–∞–≥—Ä—É–∂–µ–Ω: {len(BLACKLIST_CACHE)} –º–µ—Ä—Ç–≤—ã—Ö —É–∑–ª–æ–≤.")

def save_persistent_blacklist(new_dead_nodes):
    now_str = datetime.now().isoformat()
    with BLACKLIST_LOCK:
        for node in new_dead_nodes:
            BLACKLIST_CACHE.add(node)
            
    valid_lines = []
    with BLACKLIST_LOCK:
        for item in BLACKLIST_CACHE:
            if '|' in item: valid_lines.append(item)
            else: valid_lines.append(f"{item}|{now_str}")
            
    content = "\n".join(valid_lines) + "\n"
    atomic_save(PERSISTENT_BLACKLIST, content)

def deep_purge_files(dead_configs):
    """
    –ê–ë–°–û–õ–Æ–¢–ù–ê–Ø –ó–ê–ß–ò–°–¢–ö–ê: –§–∏–∑–∏—á–µ—Å–∫–∏ —É–¥–∞–ª—è–µ—Ç –º–µ—Ä—Ç–≤—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ –≤—Å–µ—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤.
    –¢–∞–∫–∂–µ —É–¥–∞–ª—è–µ—Ç —ç—Ç–∏ —Ö–æ—Å—Ç—ã –∏–∑ GeoIP –∫—ç—à–∞, —á—Ç–æ–±—ã –¥–∞–Ω–Ω—ã–µ –±—ã–ª–∏ –≤—Å–µ–≥–¥–∞ —Å–≤–µ–∂–∏–º–∏.
    """
    if not dead_configs: return
    
    files_to_purge = [ALL_SOURCES_FILE, "mix.txt", "sub_monster.txt", "failed_nodes.txt"]
    for c in COUNTRIES:
        files_to_purge.append(f"{c}.txt")
        
    purged_total = 0
    dead_set = set([c.strip() for c in dead_configs])
    
    # –£–¥–∞–ª–µ–Ω–∏–µ —Ö–æ—Å—Ç–æ–≤ –∏–∑ –∫—ç—à–∞ –≥–µ–æ–ª–æ–∫–∞—Ü–∏–∏
    for cfg in dead_set:
        h, _ = get_server_info(cfg)
        if h: remove_from_cache(h)
    
    for filepath in files_to_purge:
        if not os.path.exists(filepath): continue
        
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            clean_lines = []
            file_changed = False
            
            for line in lines:
                l_strip = line.strip()
                if not l_strip or l_strip.startswith('#'):
                    clean_lines.append(line)
                    continue
                
                # Base64 —Ñ–∞–π–ª—ã
                if not any(p in l_strip for p in ALLOWED_PROTOCOLS):
                    decoded = decode_base64(l_strip)
                    if decoded and any(p in decoded for p in ALLOWED_PROTOCOLS):
                        configs_in_b64 = decoded.splitlines()
                        clean_b64 = [cfg for cfg in configs_in_b64 if cfg.strip() not in dead_set]
                        if len(clean_b64) != len(configs_in_b64):
                            file_changed = True
                            purged_total += (len(configs_in_b64) - len(clean_b64))
                            if clean_b64: clean_lines.append(encode_base64("\n".join(clean_b64)) + "\n")
                        else:
                            clean_lines.append(line)
                        continue

                # –û–±—ã—á–Ω—ã–µ —Å—Å—ã–ª–∫–∏
                if l_strip in dead_set:
                    file_changed = True
                    purged_total += 1
                else:
                    clean_lines.append(line)
            
            if file_changed:
                atomic_save(filepath, "".join(clean_lines))
                
        except Exception as e:
            print(f"[ERROR] –û—à–∏–±–∫–∞ –∑–∞—á–∏—Å—Ç–∫–∏ —Ñ–∞–π–ª–∞ {filepath}: {e}")
            
    if purged_total > 0:
        print(f"üóëÔ∏è DEEP PURGE: –í—ã—Ä–µ–∑–∞–Ω–æ {purged_total} —É–ø–æ–º–∏–Ω–∞–Ω–∏–π. –ö—ç—à GeoIP —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω.")
        save_geoip_cache()

def load_processed_sources():
    if os.path.exists(PROCESSED_SOURCES_FILE):
        try:
            with open(PROCESSED_SOURCES_FILE, 'r') as f:
                return set([line.strip() for line in f if line.strip()])
        except: return set()
    return set()

def save_processed_source_hash(url):
    h = hashlib.sha256(url.encode()).hexdigest()
    try:
        with open(PROCESSED_SOURCES_FILE, 'a') as f: f.write(h + "\n")
    except: pass

# ==============================================================================
# --- –í–û–†–ö–ï–†–´ –î–õ–Ø –ú–ù–û–ì–û–ü–û–¢–û–ß–ù–û–°–¢–ò ---
# ==============================================================================

def check_worker(config, seen_lock, global_seen):
    h, p = get_server_info(config)
    if not h or not p: return None
    
    nid = f"{h}:{p}"
    
    with BLACKLIST_LOCK:
        if any(b.startswith(nid) for b in BLACKLIST_CACHE):
            return ("FAIL", nid, config)
            
    with seen_lock:
        if nid in global_seen: return None
        global_seen.add(nid)
        
    if is_node_alive(h, p): 
        return ("OK", nid, config)
    else: 
        return ("FAIL", nid, config)

def geoip_parallel_worker(cfg):
    host, _ = get_server_info(cfg)
    code = check_ip_location_smart(host)
    return (cfg, code)

# ==============================================================================
# --- –§–ò–ù–ê–õ–ò–ó–ê–¶–ò–Ø –ò –°–ò–ù–•–†–û–ù–ò–ó–ê–¶–ò–Ø ---
# ==============================================================================

def generate_static_links():
    print("\nüîó –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Å—Å—ã–ª–æ–∫ –∫–ª–∏–µ–Ω—Ç–∞...", flush=True)
    try:
        remote_url = subprocess.run(["git", "config", "--get", "remote.origin.url"], 
                                   capture_output=True, text=True).stdout.strip()
        
        if not remote_url:
            raw_base = "https://raw.githubusercontent.com/USER/REPO/main/"
        else:
            raw_base = remote_url.replace("github.com", "raw.githubusercontent.com").replace(".git", "")
            if "raw.githubusercontent.com" in raw_base:
                raw_base += "/main/"
        
        links = []
        links.append(f"üöÄ MONSTER VPN PRO SUBSCRIPTIONS üöÄ\n")
        links.append(f"üî• MIX (Text): {raw_base}mix.txt")
        links.append(f"üî• MIX (Base64): {raw_base}sub_monster.txt\n")
        links.append("üåç --- BY COUNTRIES --- üåç")
        for c in COUNTRIES:
            links.append(f"{c.upper()}: {raw_base}{c}.txt")
        
        atomic_save("LINKS_FOR_CLIENTS.txt", "\n".join(links))
    except Exception as e:
        print(f"[!] –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ —Å—Å—ã–ª–æ–∫: {e}")

def git_commit_push():
    print("\n[Git Sync] –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å –æ–±–ª–∞–∫–æ–º...", flush=True)
    try:
        subprocess.run(["git", "config", "--local", "user.name", "Monster-Ultra-Daemon"], check=True)
        subprocess.run(["git", "config", "--local", "user.email", "daemon@vpn-monster.com"], check=True)
        subprocess.run(["git", "add", "."], check=True)
        
        status = subprocess.run(["git", "status", "--porcelain"], capture_output=True, text=True).stdout.strip()
        if not status:
            print("[Git Sync] –ò–∑–º–µ–Ω–µ–Ω–∏–π –≤ –±–∞–∑–µ –Ω–µ—Ç.")
            return

        timestamp = datetime.now().strftime('%d/%m/%Y %H:%M:%S')
        subprocess.run(["git", "commit", "-m", f"‚ö° Auto-Sync Monster Engine: {timestamp}"], check=True)
        
        res = subprocess.run(["git", "push", "origin", "main"], capture_output=True, text=True)
        if res.returncode != 0:
            subprocess.run(["git", "push", "origin", "main", "--force"], check=True)
            
        print(f"[Git Sync] ‚úÖ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {timestamp}")
    except Exception as e: 
        print(f"[Git Sync] ‚ùå –û—à–∏–±–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏: {e}")

def save_and_organize(structured, final_mix_list, failed_list):
    for country in COUNTRIES:
        file_name = f"{country}.txt"
        configs = structured.get(country, [])
        valid = sorted(list(set(configs)))
        content = "\n".join(valid) if valid else f"# No active nodes for {country}\n"
        atomic_save(file_name, content)

    valid_mix = sorted(list(set(final_mix_list)))
    atomic_save("mix.txt", "\n".join(valid_mix) if valid_mix else "# No active nodes found\n")
    atomic_save("sub_monster.txt", encode_base64("\n".join(valid_mix)) if valid_mix else "")
    
    valid_failed = sorted(list(set(failed_list)))
    atomic_save("failed_nodes.txt", "\n".join(valid_failed) if valid_failed else "# No failed nodes\n")
    atomic_save("sub_failed.txt", encode_base64("\n".join(valid_failed)) if valid_failed else "")

# ==============================================================================
# --- –ì–õ–ê–í–ù–´–ô –ü–†–û–¶–ï–°–° –û–ë–ù–û–í–õ–ï–ù–ò–Ø (CORE ENGINE) ---
# ==============================================================================

def run_update_cycle(trigger_reason="–¢–∞–π–º–µ—Ä"):
    start_time = datetime.now()
    print(f"\n{'='*70}")
    print(f"üî• –ó–ê–ü–£–°–ö –¶–ò–ö–õ–ê MONSTER ENGINE ULTRA (V 4.1.0)")
    print(f"‚è±Ô∏è –¢—Ä–∏–≥–≥–µ—Ä: {trigger_reason}")
    print(f"{'='*70}\n")
    
    load_geoip_cache()
    load_persistent_blacklist()
    processed_hashes = load_processed_sources()
    
    raw_configs = []
    new_sources = []
    
    # 1. –ß–∏—Ç–∞–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏
    if os.path.exists(ALL_SOURCES_FILE):
        with open(ALL_SOURCES_FILE, 'r', encoding='utf-8') as f:
            for line in f:
                l_strip = line.strip()
                if not l_strip or l_strip.startswith('#'): continue
                
                if l_strip.startswith('http'):
                    h = hashlib.sha256(l_strip.encode()).hexdigest()
                    if h not in processed_hashes:
                        new_sources.append(l_strip)
                elif any(p in l_strip for p in ALLOWED_PROTOCOLS):
                    raw_configs.append(l_strip)
    
    # 2. –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—É—â–∏–µ —É–∑–ª—ã –∏–∑ —Ñ–∞–π–ª–æ–≤ —Å—Ç—Ä–∞–Ω
    for c in COUNTRIES:
        fn = f"{c}.txt"
        if os.path.exists(fn):
            with open(fn, 'r', encoding='utf-8') as f:
                raw_configs.extend([l.strip() for l in f if l.strip() and not l.startswith('#')])

    # 3. –ü–∞—Ä—Å–∏–º –≤–Ω–µ—à–Ω–∏–µ —Å—Å—ã–ª–∫–∏
    if new_sources:
        print(f"üì° –ó–∞–≥—Ä—É–∑–∫–∞ {len(new_sources)} –≤–Ω–µ—à–Ω–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤...")
        for url in new_sources:
            if SHOULD_EXIT: break
            try:
                r = requests.get(url, timeout=15, headers={'User-Agent': get_random_ua()})
                text = r.text
                if not any(p in text for p in ALLOWED_PROTOCOLS):
                    decoded = decode_base64(text)
                    if decoded: text = decoded
                
                pattern = r'(?:' + '|'.join(ALLOWED_PROTOCOLS).replace('://', '') + r')://[^\s#"\'<>,]+'
                found = re.findall(pattern, text)
                raw_configs.extend(found)
                save_processed_source_hash(url)
            except Exception as e:
                print(f"  [!] –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {url}: {e}")

    total_configs = list(set(raw_configs))
    if not total_configs:
        print("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.")
        return

    # 4. TCP Ping
    valid_nodes = []
    dead_configs_for_purge = []
    new_dead_nodes = set()
    global_seen = set()
    seen_lock = threading.Lock()
    
    print(f"‚ö° TCP Ping ({THREAD_COUNT} –ø–æ—Ç–æ–∫–æ–≤)...", flush=True)
    with ThreadPoolExecutor(max_workers=THREAD_COUNT) as executor:
        futures = [executor.submit(check_worker, c, seen_lock, global_seen) for c in total_configs]
        for i, future in enumerate(as_completed(futures)):
            if SHOULD_EXIT: break
            try:
                res = future.result()
                if res:
                    status, nid, config = res
                    if status == "OK": valid_nodes.append(config)
                    else:
                        new_dead_nodes.add(nid)
                        dead_configs_for_purge.append(config)
            except: continue

    # 5. –°–ò–ù–•–†–û–ù–ò–ó–ò–†–û–í–ê–ù–ù–ê–Ø –ó–ê–ß–ò–°–¢–ö–ê (–ú–µ—Ä—Ç–≤—ã–µ —É–∑–ª—ã —É–¥–∞–ª—è—é—Ç—Å—è –∏–∑ –ö–≠–®–ê –∏ –§–ê–ô–õ–û–í)
    if dead_configs_for_purge:
        save_persistent_blacklist(new_dead_nodes)
        deep_purge_files(dead_configs_for_purge)

    # 6. GeoIP –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è (–ò–°–ü–û–õ–¨–ó–£–ï–¢ –£–ú–ù–´–ô –ö–≠–®)
    structured_data = {c: [] for c in COUNTRIES}
    final_mix = []
    
    if valid_nodes:
        print(f"üåç GeoIP –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è ({GEOIP_PARALLEL_LEVEL} –ø–æ—Ç–æ–∫–æ–≤)...", flush=True)
        random.shuffle(valid_nodes)
        queue = valid_nodes[:GEOIP_LIMIT_PER_RUN]
        
        with ThreadPoolExecutor(max_workers=GEOIP_PARALLEL_LEVEL) as geo_executor:
            geo_futures = [geo_executor.submit(geoip_parallel_worker, cfg) for cfg in queue]
            for i, f in enumerate(as_completed(geo_futures)):
                if SHOULD_EXIT: break
                try:
                    cfg, code = f.result()
                    matched = False
                    if code and code != "UN":
                        for c_name, c_info in COUNTRIES.items():
                            if code in [c_info["code"], c_info.get("alt_code"), c_info.get("extra")]:
                                b_cfg = beautify_config(cfg, c_name)
                                structured_data[c_name].append(b_cfg)
                                final_mix.append(b_cfg)
                                matched = True
                                break
                    if not matched:
                        final_mix.append(beautify_config(cfg, None, fallback_code=code))
                except: continue

    # 7. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫—ç—à–∞ –∏ –¥–∞–Ω–Ω—ã—Ö
    save_geoip_cache()
    save_and_organize(structured_data, final_mix, dead_configs_for_purge)
    generate_static_links()
    git_commit_push()
    
    gc.collect()
    print(f"\nüèÅ –¶–ò–ö–õ –ó–ê–í–ï–†–®–ï–ù. –í—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã: {datetime.now() - start_time}.")

# ==============================================================================
# --- –î–ï–ú–û–ù-–ü–ï–¢–õ–Ø (DAEMON LOOP) ---
# ==============================================================================

def start_daemon():
    if os.path.exists(LOCK_FILE):
        print(f"[–ö–†–ò–¢] Lock-—Ñ–∞–π–ª {LOCK_FILE} —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.")
        return
        
    with open(LOCK_FILE, 'w') as f: f.write(str(os.getpid()))
    
    print(f"\n{'*'*70}")
    print(f"üõ°Ô∏è VPN MONSTER DAEMON 4.1.0 –ê–ö–¢–ò–í–ï–ù üõ°Ô∏è")
    print(f"–°–∏—Å—Ç–µ–º–∞ —É–º–Ω–æ–≥–æ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –≤–∫–ª—é—á–µ–Ω–∞.")
    print(f"{'*'*70}\n")
    
    last_run_time = datetime.min
    last_sources_mod_time = get_file_mod_time(ALL_SOURCES_FILE)
    
    try:
        while not SHOULD_EXIT:
            now = datetime.now()
            trigger_reason = None
            
            if now - last_run_time >= timedelta(hours=UPDATE_INTERVAL_HOURS):
                trigger_reason = f"–ü–ª–∞–Ω–æ–≤–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ ({UPDATE_INTERVAL_HOURS}—á)"
            
            current_mod_time = get_file_mod_time(ALL_SOURCES_FILE)
            if current_mod_time > last_sources_mod_time:
                trigger_reason = f"–ò–∑–º–µ–Ω–µ–Ω–∏—è –≤ {ALL_SOURCES_FILE}"
                last_sources_mod_time = current_mod_time
                
            if trigger_reason:
                run_update_cycle(trigger_reason)
                last_run_time = datetime.now()
                last_sources_mod_time = get_file_mod_time(ALL_SOURCES_FILE)
                
            time.sleep(WATCHER_INTERVAL_SEC)
            
    finally:
        if os.path.exists(LOCK_FILE):
            try: os.remove(LOCK_FILE)
            except: pass

if __name__ == "__main__":
    try:
        socket.setdefaulttimeout(PORT_TIMEOUT)
        start_daemon()
    except Exception as e:
        print(f"\n[FATAL ERROR]: {e}")
        if os.path.exists(LOCK_FILE):
            try: os.remove(LOCK_FILE)
            except: pass
        sys.exit(1)
