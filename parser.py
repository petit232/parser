import os
import json
import asyncio
import aiohttp
import time
import re
import socket
import geoip2.database
from datetime import datetime
from urllib.parse import urlparse, parse_qs, urlencode, urlunparse

# --- CONFIGURATION ---
SOURCE_FILE = 'all_sources.txt'
STATE_FILE = 'monster_state.json'
GEOIP_DB = 'GeoLite2-Country.mmdb'
LINKS_INFO_FILE = 'LINKS_FOR_CLIENTS.txt'
BATCH_SIZE = 500  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ—Ä–≤–µ—Ä–æ–≤ –¥–ª—è –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –ø–∏–Ω–≥–∞
TIMEOUT = 5       # –¢–∞–π–º–∞—É—Ç –ø–∏–Ω–≥–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
MAX_NODES_PER_COUNTRY = 500 # –õ–∏–º–∏—Ç –Ω–æ–¥ –Ω–∞ –æ–¥–∏–Ω —Ñ–∞–π–ª —Å—Ç—Ä–∞–Ω—ã

# –ú–∞–ø–ø–∏–Ω–≥ —Å—Ç—Ä–∞–Ω –Ω–∞ —Ñ–∞–π–ª—ã
COUNTRY_MAP = {
    'RU': 'russia.txt',
    'BY': 'belarus.txt',
    'FI': 'finland.txt',
    'FR': 'france.txt',
    'DE': 'germany.txt',
    'HK': 'hongkong.txt',
    'KZ': 'kazakhstan.txt',
    'NL': 'netherlands.txt',
    'PL': 'poland.txt',
    'SG': 'singapore.txt',
    'SE': 'sweden.txt',
    'GB': 'uk.txt',
    'US': 'usa.txt',
}
DEFAULT_MIX = 'mix.txt'

class MonsterParser:
    def __init__(self):
        self.state = self.load_state()
        self.geo_reader = None
        if os.path.exists(GEOIP_DB):
            self.geo_reader = geoip2.database.Reader(GEOIP_DB)
        
        # –†–µ–≥—É–ª—è—Ä–∫–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ö–æ—Å—Ç–∞ –∏ –ø–æ—Ä—Ç–∞
        self.ip_pattern = re.compile(r'@?([\w\.-]+):(\d+)')

    def load_state(self):
        if os.path.exists(STATE_FILE):
            try:
                with open(STATE_FILE, 'r') as f:
                    return json.load(f)
            except:
                pass
        return {"last_index": 0, "processed_total": 0, "history": []}

    def save_state(self):
        with open(STATE_FILE, 'w') as f:
            json.dump(self.state, f, indent=4)

    def get_ip_from_link(self, link):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ö–æ—Å—Ç –∏–∑ —Å—Å—ã–ª–æ–∫ vless/vmess/ss/trojan"""
        try:
            match = self.ip_pattern.search(link)
            if match:
                return match.group(1)
        except Exception:
            pass
        return None

    def wrap_for_russia(self, link):
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞—â–∏—Ç—ã –æ—Ç DPI (Fragment, Mux, Padding) –¥–ª—è —Ä–∞–±–æ—Ç—ã –≤ –†–§.
        –ü—Ä–∏–æ—Ä–∏—Ç–µ–∑–∏—Ä—É–µ—Ç Reality.
        """
        try:
            parsed = urlparse(link)
            query = parse_qs(parsed.query)
            
            # –ï—Å–ª–∏ —ç—Ç–æ Reality - –æ–Ω —É–∂–µ –∑–∞—â–∏—â–µ–Ω, –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            if 'reality' in str(query.get('security', [])).lower():
                return link 

            # –î–ª—è VLESS, VMESS, Trojan –¥–æ–±–∞–≤–ª—è–µ–º Fragment (–∑–∞—â–∏—Ç–∞ –æ—Ç DPI)
            if parsed.scheme in ['vless', 'vmess', 'trojan']:
                # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø–∞–∫–µ—Ç–æ–≤
                query['fragment'] = ['10-20,30-50']
                query['mux'] = ['enable=true&concurrency=8']
                
                # –ï—Å–ª–∏ –Ω–µ—Ç TLS, –Ω–æ –ø—Ä–æ—Ç–æ–∫–æ–ª –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç - –ø—Ä–æ–±—É–µ–º –¥–æ–±–∞–≤–∏—Ç—å –º–∞—Å–∫–∏—Ä–æ–≤–∫—É
                if 'security' not in query:
                    query['security'] = ['tls']
                
                # –°–æ–±–∏—Ä–∞–µ–º —Å—Å—ã–ª–∫—É –æ–±—Ä–∞—Ç–Ω–æ
                new_query = urlencode(query, doseq=True)
                new_parts = list(parsed)
                new_parts[4] = new_query
                return urlunparse(new_parts)
                
            return link
        except:
            return link

    def get_link_score(self, link):
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å –∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ –¥–ª—è –†–§"""
        score = 0
        link_low = link.lower()
        if 'reality' in link_low: score += 1000
        if 'vless' in link_low: score += 500
        if 'trojan' in link_low: score += 400
        if 'vmess' in link_low: score += 300
        if 'fragment' in link_low: score += 100
        return score

    async def check_node(self, session, link):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —É–∑–ª–∞ (TCP Ping) –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"""
        host = self.get_ip_from_link(link)
        if not host:
            return None, 9999
        
        start_time = time.time()
        try:
            # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π —Ä–µ–∑–æ–ª–≤ DNS
            loop = asyncio.get_event_loop()
            ip_addr = await loop.run_in_executor(None, socket.gethostbyname, host)
            
            # –ü–æ–ø—ã—Ç–∫–∞ TCP —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
            conn = asyncio.open_connection(ip_addr, 443)
            reader, writer = await asyncio.wait_for(conn, timeout=TIMEOUT)
            writer.close()
            await writer.wait_closed()
            
            ping_ms = int((time.time() - start_time) * 1000)
            return ip_addr, ping_ms
        except:
            return None, 9999

    def get_country(self, ip):
        if not self.geo_reader:
            return None
        try:
            response = self.geo_reader.country(ip)
            return response.country.iso_code
        except:
            return None

    def generate_static_links(self):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ñ–∞–π–ª —Å–æ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–º–∏ —Å—Å—ã–ª–∫–∞–º–∏ –Ω–∞ –ø–æ–¥–ø–∏—Å–∫–∏ –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞"""
        repo_full_name = os.getenv('GITHUB_REPOSITORY', 'USER/REPO')
        base_url = f"https://raw.githubusercontent.com/{repo_full_name}/main"
        
        content = []
        content.append("‚ö° Monster Engine: –í–∞—à–∏ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ –ø–æ–¥–ø–∏—Å–∫–∏")
        content.append(f"–û–±–Ω–æ–≤–ª–µ–Ω–æ: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}")
        content.append("-" * 50)
        content.append(f"GLOBAL MIX: {base_url}/sub_monster.txt")
        content.append("-" * 50)
        
        for country_code, filename in sorted(COUNTRY_MAP.items()):
            content.append(f"{country_code} ({filename.replace('.txt', '')}): {base_url}/{filename}")
            
        with open(LINKS_INFO_FILE, 'w', encoding='utf-8') as f:
            f.write('\n'.join(content))
        print(f"‚úÖ –§–∞–π–ª —Å–æ —Å—Å—ã–ª–∫–∞–º–∏ –æ–±–Ω–æ–≤–ª–µ–Ω: {LINKS_INFO_FILE}")

    async def run(self):
        if not os.path.exists(SOURCE_FILE):
            print(f"‚ùå –û—à–∏–±–∫–∞: {SOURCE_FILE} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
            return

        with open(SOURCE_FILE, 'r', encoding='utf-8') as f:
            links = [line.strip() for line in f if line.strip()]

        # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è
        links = list(dict.fromkeys(links))
        total_links = len(links)
        
        start = self.state.get("last_index", 0)
        if start >= total_links: start = 0
        
        end = min(start + 5000, total_links)
        current_batch = links[start:end]
        
        print(f"üöÄ Monster Engine: –û–±—Ä–∞–±–æ—Ç–∫–∞ {len(current_batch)} –Ω–æ–¥ ({start} - {end} –∏–∑ {total_links})")

        results = []
        async with aiohttp.ClientSession() as session:
            for i in range(0, len(current_batch), BATCH_SIZE):
                sub_batch = current_batch[i:i+BATCH_SIZE]
                tasks = [self.check_node(session, link) for link in sub_batch]
                checked = await asyncio.gather(*tasks)
                
                for link, (ip, ping) in zip(sub_batch, checked):
                    if ip:
                        # "–ó–∞–≤–æ—Ä–∞—á–∏–≤–∞–µ–º" –Ω–æ–¥—É –¥–ª—è –æ–±—Ö–æ–¥–∞ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫
                        protected_link = self.wrap_for_russia(link)
                        country = self.get_country(ip)
                        results.append({
                            "link": protected_link,
                            "ip": ip,
                            "ping": ping,
                            "country": country,
                            "score": self.get_link_score(protected_link)
                        })

        # --- –ì–õ–û–ë–ê–õ–¨–ù–ê–Ø –°–ò–ù–•–†–û–ù–ò–ó–ê–¶–ò–Ø –ò –û–ß–ò–°–¢–ö–ê ---
        living_links_original = {current_batch[i] for i, (ip, p) in enumerate(checked) if ip}
        dead_links = set(current_batch) - living_links_original
        
        file_updates = {filename: [] for filename in set(COUNTRY_MAP.values()) | {DEFAULT_MIX}}
        
        for res in results:
            target_file = COUNTRY_MAP.get(res['country'], DEFAULT_MIX)
            file_updates[target_file].append(res)

        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ —Å—Ç—Ä–∞–Ω —Å —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–æ–π –ø–æ Score (—Å–Ω–∞—á–∞–ª–∞ Reality) –∏ Ping
        for filename, new_data in file_updates.items():
            current_nodes_map = {} # link -> score_data
            
            if os.path.exists(filename):
                with open(filename, 'r', encoding='utf-8') as f:
                    for l in f:
                        line = l.strip()
                        if line and line not in dead_links:
                            # –î–ª—è —Å—Ç–∞—Ä—ã—Ö —Å—Ç—Ä–æ–∫ —Å—á–∏—Ç–∞–µ–º –±–∞–∑–æ–≤—ã–π score
                            current_nodes_map[line] = self.get_link_score(line)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –∂–∏–≤—ã–µ –Ω–æ–¥—ã
            for item in new_data:
                current_nodes_map[item['link']] = item['score']
            
            # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞: —Å–Ω–∞—á–∞–ª–∞ –ø–æ Score (–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å), –ø–æ—Ç–æ–º –ø–æ Ping (—Å–∫–æ—Ä–æ—Å—Ç—å)
            sorted_links = sorted(current_nodes_map.keys(), key=lambda x: current_nodes_map[x], reverse=True)
            
            with open(filename, 'w', encoding='utf-8') as f:
                f.write('\n'.join(sorted_links[:MAX_NODES_PER_COUNTRY]) + '\n')

        # –û—á–∏—Å—Ç–∫–∞ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ SOURCE_FILE
        remaining_links = [l for l in links if l not in dead_links]
        with open(SOURCE_FILE, 'w', encoding='utf-8') as f:
            f.write('\n'.join(remaining_links) + '\n')

        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ–±—â–µ–≥–æ —Ñ–∞–π–ª–∞ –ø–æ–¥–ø–∏—Å–∫–∏
        with open('sub_monster.txt', 'w', encoding='utf-8') as f:
            all_live_with_score = {l: self.get_link_score(l) for l in remaining_links}
            sorted_sub = sorted(all_live_with_score.keys(), key=lambda x: all_live_with_score[x], reverse=True)
            f.write('\n'.join(sorted_sub[:5000]))

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫ —Å—Å—ã–ª–æ–∫ –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞
        self.generate_static_links()

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        self.state["last_index"] = end if end < total_links else 0
        self.state["processed_total"] += len(current_batch)
        self.state["last_run"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        self.save_state()
        
        print(f"‚úÖ –ë–∞—Ç—á –∑–∞–≤–µ—Ä—à–µ–Ω. –ù–∞–π–¥–µ–Ω–æ {len(results)} –∂–∏–≤—ã—Ö. –£–¥–∞–ª–µ–Ω–æ {len(dead_links)} –º–µ—Ä—Ç–≤—ã—Ö.")

if __name__ == "__main__":
    parser = MonsterParser()
    asyncio.run(parser.run())
